{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "classification-predict (2).ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie6g76gsUaww"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i0yHv_xVUawx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from catboost import Pool, CatBoostClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i362Sk1Uaw2"
      },
      "source": [
        "## Importing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "qq3VYisCUaw3"
      },
      "source": [
        "train =  pd.read_csv('../input/climate-change-edsa2020-21/train.csv')\n",
        "test = pd.read_csv('../input/climate-change-edsa2020-21/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz3rUCciUaw7"
      },
      "source": [
        "## Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MEGIeSLxUaw8",
        "outputId": "db2abfb5-7fb2-4d2a-e4be-cf073e1daeeb"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sentiment                                            message  tweetid\n",
              "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
              "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
              "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
              "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
              "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
              "      <td>625221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
              "      <td>126103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
              "      <td>698562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
              "      <td>573736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
              "      <td>466954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lB1ySsdAUaw_",
        "outputId": "9fea039f-0afa-4d22-fcc8-96e78912c1a0"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15819 entries, 0 to 15818\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   sentiment  15819 non-null  int64 \n",
            " 1   message    15819 non-null  object\n",
            " 2   tweetid    15819 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 370.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ib3iBPN7UaxC",
        "outputId": "2deb44c3-1832-47e1-d8c5-cfb86eb6c010"
      },
      "source": [
        "train.sentiment.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    8530\n",
              " 2    3640\n",
              " 0    2353\n",
              "-1    1296\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvvSPICmUaxG"
      },
      "source": [
        "### Text Cleaning\n",
        "Removing the noise in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ROPgSMrJUaxH"
      },
      "source": [
        "train['message'] = train['message'].str.lower()\n",
        "test['message'] = test['message'].str.lower()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UEM_VmZcUaxK"
      },
      "source": [
        "stemmer=PorterStemmer()\n",
        "\n",
        "def remove_pattern(input_txt):\n",
        "    input_txt = re.sub(\"\\\\W\",\" \",input_txt)\n",
        "    input_txt = re.sub(\"\\\\s+(in|the|all|for|and|on)\\\\s+\",\" \",input_txt)\n",
        "    \n",
        "    \n",
        "    # stem words\n",
        "    words = re.split(\"\\\\s+\",input_txt)\n",
        "    stemmed_words = [stemmer.stem(word=word) for word in words]\n",
        "    \n",
        "    return ' '.join(stemmed_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "82Db2P-5UaxO"
      },
      "source": [
        "def tokenizer(input_txt):\n",
        "    text=re.sub(\"(\\\\W)\",\" \\\\1 \",input_txt)\n",
        "\n",
        "    # split based on whitespace\n",
        "    return re.split(\"\\\\s+\",input_txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R_Ii9ZDlUaxR",
        "outputId": "861adee9-50c6-4f68-ca07-3f6f877febe1"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sentiment                                            message  tweetid\n",
              "0          1  polyscimajor epa chief doesn't think carbon di...   625221\n",
              "1          1  it's not like we lack evidence of anthropogeni...   126103\n",
              "2          2  rt @rawstory: researchers say we have three ye...   698562\n",
              "3          1  #todayinmaker# wired : 2016 was a pivotal year...   573736\n",
              "4          1  rt @soynoviodetodas: it's 2016, and a racist, ...   466954"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
              "      <td>625221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
              "      <td>126103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>rt @rawstory: researchers say we have three ye...</td>\n",
              "      <td>698562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>#todayinmaker# wired : 2016 was a pivotal year...</td>\n",
              "      <td>573736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>rt @soynoviodetodas: it's 2016, and a racist, ...</td>\n",
              "      <td>466954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SmDa1BoIUaxT"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import re \n",
        "stop = stopwords.words('english')\n",
        "remove_words = ['rt']\n",
        "\n",
        "# Exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
        "train[\"message\"] = train[\"message\"].apply(lambda x: ' '.join([word for word in x.split() if word[0]!='#' and word[0]!='@'])) #Remove # and @\n",
        "train['message'] = train['message'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))            #Remove stopwords\n",
        "train['message'] = train['message'].apply(lambda x: ' '.join([word for word in x.split() if word not in (remove_words)]))    #Remove additional words\n",
        "\n",
        "test[\"message\"] = test[\"message\"].apply(lambda x: ' '.join([word for word in x.split() if word[0]!='#' and word[0]!='@']))\n",
        "test['message'] = test['message'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "test['message'] = test['message'].apply(lambda x: ' '.join([word for word in x.split() if word not in (remove_words)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yvlfWS4EUaxW",
        "outputId": "dba8d813-f58c-48d2-8073-99f11375a86e"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sentiment                                            message  tweetid\n",
              "0          1  polyscimajor epa chief doesn't think carbon di...   625221\n",
              "1          1  it's not like we lack evidence of anthropogeni...   126103\n",
              "2          2  rt @rawstory: researchers say we have three ye...   698562\n",
              "3          1  #todayinmaker# wired : 2016 was a pivotal year...   573736\n",
              "4          1  rt @soynoviodetodas: it's 2016, and a racist, ...   466954"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
              "      <td>625221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
              "      <td>126103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>rt @rawstory: researchers say we have three ye...</td>\n",
              "      <td>698562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>#todayinmaker# wired : 2016 was a pivotal year...</td>\n",
              "      <td>573736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>rt @soynoviodetodas: it's 2016, and a racist, ...</td>\n",
              "      <td>466954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-2KCdc5UaxZ"
      },
      "source": [
        "### Spliting the training data into X & Y variables\n",
        "We split the training data into the X variables which will be the message(tweets that are tweeted out) and Y variables which will be the sentiment(If a person tweeting believes in Climate Change or not).\n",
        "\n",
        "Then we transform out data into numbers using CountVectorizer into a language that the computer can easily understand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3Zzf83zfUaxa"
      },
      "source": [
        "y = train['sentiment']\n",
        "X = train['message']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "19aV9qCPUaxf",
        "outputId": "8689ac65-9888-41a2-b1e5-1221fd87bb33"
      },
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1,2),tokenizer=tokenizer, min_df=2,max_df=0.70,analyzer='word',smooth_idf=False, preprocessor=remove_pattern ,stop_words=\"english\")\n",
        "X_cnt_vectorized = vectorizer.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_K9yA0gUaxj"
      },
      "source": [
        "### Perfomance validation for train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NN5J79LIUaxj"
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X_cnt_vectorized,y,test_size=0.08,shuffle=True, random_state=23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZQIc4OCUaxm"
      },
      "source": [
        "### Training the different train data models and F1 Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjjf8Ca9Uaxn"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uQICz9tlUaxo"
      },
      "source": [
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rfc.fit(X_train, y_train)\n",
        "rfc_cnt_pred = rfc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "79U0ZVQyUaxr",
        "outputId": "b43687ab-f91a-4d19-a241-2b8815090c2d"
      },
      "source": [
        "f1_score(y_test, rfc_cnt_pred, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5667321767416644"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8mO5l-1Uaxv"
      },
      "source": [
        "#### SVM Linear Classifier Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Zg_Po9jGUaxv"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "svm_lin = svm.LinearSVC()\n",
        "svm_lin.fit(X_train, y_train)\n",
        "svm_cnt_pred = svm_lin.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JaDHnCKyUaxy",
        "outputId": "0b99e725-ff2e-4b1b-c6df-4f4a261e294c"
      },
      "source": [
        "f1_score(y_test, svm_cnt_pred, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6683787033069274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxiThCbeUax0"
      },
      "source": [
        "#### SGD Classifier Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "efpibRyUUax0"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = SGDClassifier()\n",
        "sgd.fit(X_train, y_train)\n",
        "sgd_cnt_pred = sgd.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "61h7_-KeUax3",
        "outputId": "30dd59a8-2889-4d4e-e30d-a5781278c2c2"
      },
      "source": [
        "f1_score(y_test, sgd_cnt_pred, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6317591801921397"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAxBe-sOUax5"
      },
      "source": [
        "#### Linear Regression Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "E58XEwidUax5",
        "outputId": "932b2ba8-32e9-483c-ccb3-5b35611848c3"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(random_state = 23)\n",
        "lr.fit(X_train, y_train)\n",
        "lr_cnt_pred = lr.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Q6aS9FGoUax8",
        "outputId": "4a349439-2ab7-4b13-9434-3223499b53fc"
      },
      "source": [
        "f1_score(y_test, lr_cnt_pred, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6088427405216152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtFO3H4YUayA"
      },
      "source": [
        "## Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJh2yBgZUayB"
      },
      "source": [
        "### Spliting the training data into X & Y variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ER02qkdwUayB"
      },
      "source": [
        "test_X = test['message']\n",
        "test_cnt_vect = vectorizer.transform(test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQJxH2SQUayD"
      },
      "source": [
        "### Testing the test model data and F1 Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snOrUD0XUayE"
      },
      "source": [
        "#### Random Forest Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FwWd5fKHUayF"
      },
      "source": [
        "y_cnt_pred = rfc.predict(test_cnt_vect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWC5Xts6UayI"
      },
      "source": [
        "#### SVM Linear Classifier Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oQq7y1C-UayJ"
      },
      "source": [
        "y_cnt_pred = svm_lin.predict(test_cnt_vect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nBOq4WPUayL"
      },
      "source": [
        "#### SGD Classifier Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ix9lxrU-UayL"
      },
      "source": [
        "y_cnt_pred = sgd.predict(test_cnt_vect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_duxueoIUayO"
      },
      "source": [
        "#### Logistic Regression Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Q_WtD5N5UayO"
      },
      "source": [
        "y_cnt_pred = lr.predict(test_cnt_vect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6cBpXyLUayQ"
      },
      "source": [
        "### Final Test predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uwkf0Du4UayR"
      },
      "source": [
        "test['sentiment'] = y_cnt_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BsPtIKBvUayT",
        "outputId": "c2e65cfd-3be3-484d-8800-a3bed6c82db6"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             message  tweetid  sentiment\n",
              "0  europe will now be looking to china to make su...   169760          1\n",
              "1  combine this with the polling of staffers re c...    35326          1\n",
              "2  the scary, unimpeachable evidence that climate...   224985          1\n",
              "3  @karoli @morgfair @osborneink @dailykos \\nputi...   476263          1\n",
              "4  rt @fakewillmoore: 'female orgasms cause globa...   872928          0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>europe will now be looking to china to make su...</td>\n",
              "      <td>169760</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>combine this with the polling of staffers re c...</td>\n",
              "      <td>35326</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the scary, unimpeachable evidence that climate...</td>\n",
              "      <td>224985</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@karoli @morgfair @osborneink @dailykos \\nputi...</td>\n",
              "      <td>476263</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rt @fakewillmoore: 'female orgasms cause globa...</td>\n",
              "      <td>872928</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2MLPjFwUayV"
      },
      "source": [
        "## Creating an output csv for submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EjmNMlQWUayW"
      },
      "source": [
        "test[['tweetid','sentiment']].to_csv('testsubmission30.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}